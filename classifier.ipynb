{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925a8aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/nilt43hyl1dx82k/dataset.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip dataset.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da929764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input \n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a29fc",
   "metadata": {},
   "source": [
    "# Building our Model to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e029a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with pre trained model \n",
    "\n",
    "base_model = MobileNet( input_shape=(224,224,3), include_top= False )\n",
    "\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(units=7 , activation='softmax' )(x)\n",
    "\n",
    "# creating our model.\n",
    "model = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df80914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= categorical_crossentropy , metrics=['accuracy']  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b6411",
   "metadata": {},
   "source": [
    "# Preparing our model using data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f645d886",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 53] The network path was not found: '//images//train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\3624116866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m train_data = train_datagen.flow_from_directory(directory= \"//images//train\", \n\u001b[0;32m      9\u001b[0m                                                \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                                   )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             dtype=dtype)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 53] The network path was not found: '//images//train'"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "     zoom_range = 0.2, \n",
    "     shear_range = 0.2, \n",
    "     horizontal_flip=True, \n",
    "     rescale = 1./255\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(directory= \"//content//train\", \n",
    "                                               target_size=(224,224), \n",
    "                                               batch_size=32,\n",
    "                                  )\n",
    "\n",
    "\n",
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1./255 )\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(directory= \"//content//test\", \n",
    "                                           target_size=(224,224), \n",
    "                                           batch_size=32,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b71d5d",
   "metadata": {},
   "source": [
    "# Visualizing the data to train data gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ce046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize the images in the traing data denerator \n",
    "\n",
    "t_img , label = train_data.next()\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# function when called will prot the images \n",
    "def plotImages(img_arr, label):\n",
    "  \"\"\"\n",
    "  input  :- images array \n",
    "  output :- plots the images \n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  for im, l in zip(img_arr,label) :\n",
    "    plt.imshow(im)\n",
    "    plt.title(im.shape)\n",
    "    plt.axis = False\n",
    "    plt.show()\n",
    "    \n",
    "    count += 1\n",
    "    if count == 10:\n",
    "      break\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# function call to plot the images \n",
    "plotImages(t_img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69028080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## having early stopping and model check point \n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
    "\n",
    "# model check point\n",
    "mc = ModelCheckpoint(filepath=\"best_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
    "\n",
    "# puting call back in a list \n",
    "call_back = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a10f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_data, \n",
    "                           steps_per_epoch= 10, \n",
    "                           epochs= 30, \n",
    "                           validation_data= val_data, \n",
    "                           validation_steps= 8, \n",
    "                           callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27048903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best fit model \n",
    "from keras.models import load_model\n",
    "model = load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "h =  hist.history\n",
    "h.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['accuracy'])\n",
    "plt.plot(h['val_accuracy'] , c = \"red\")\n",
    "plt.title(\"acc vs v-acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35543783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['loss'])\n",
    "plt.plot(h['val_loss'] , c = \"red\")\n",
    "plt.title(\"loss vs v-loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to map o/p values \n",
    "op = dict(zip( train_data.class_indices.values(), train_data.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for the image to see if it predics correct class\n",
    "\n",
    "path = \"/content/test/angry/PrivateTest_1054527.jpg\"\n",
    "img = load_img(path, target_size=(224,224) )\n",
    "\n",
    "i = img_to_array(img)/255\n",
    "input_arr = np.array([i])\n",
    "input_arr.shape\n",
    "\n",
    "pred = np.argmax(model.predict(input_arr))\n",
    "\n",
    "print(f\" the image is of {op[pred]}\")\n",
    "\n",
    "# to display the image  \n",
    "plt.imshow(input_arr[0])\n",
    "plt.title(\"input image\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
